{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07173b14",
   "metadata": {},
   "source": [
    "<img width=\"300px\" src=\"https://mlflow.org/docs/latest/_static/MLflow-logo-final-black.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578bdc7",
   "metadata": {},
   "source": [
    "# Why Mlflow?\n",
    "\n",
    "A machine learning product consists is not only depend on code, as standard software development does. It is a combination of not only code, but also the input data and model parameters. Organizations need to:\n",
    "\n",
    "- Version control the data used to fuel ML models;\n",
    "- Perform model and experiment tracking and versioning;\n",
    "- Systematically optimize models through hyperparameter optimization;\n",
    "- Deploy and monitor models in production environments and keep track of the performance.\n",
    "\n",
    "MLOps is the name given to the processes and tools developed to manage all these components. \n",
    "In recent years, the number of tools has been growing rapidly.  \n",
    "While there are a number of tools currently available for all these different purposes, Mlflow offers a set of features for individuals and teams in an attempt to solve some of these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca6b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T18:38:23.621956Z",
     "start_time": "2021-11-28T18:38:23.609000Z"
    }
   },
   "source": [
    "**Mlflow** is an open-source platform, backed by Databricks, for managing the lifecycle of machine learning models, through four different pillars:\n",
    "\n",
    "- By tracking experiments to compare results (**Tracking**);\n",
    "- By allowing data scientists and ML engineers to create reusable machine learning code (**Projects**);\n",
    "- By defining a standard format for packaging models and send them to diverse deployment tools (**Models**);\n",
    "- By providing a centralized repository to collaborative manage the lifecycle of models through versioning, stage transitions and annotations (**Registry**).\n",
    "\n",
    "Besides providing SDK for common languages (Python, R, Java, Julia), and good integration with popular ML frameworks, such as Scikit-learn, Tensorflow, behond others, it is completely **language and library-agnostic**. One can use it with any framework and programming language, since it also provides a REST interface for exchanging metadata with the server.\n",
    "\n",
    "<img src=\"https://www.ambiata.com/images/blog/mlops-tools_files/task-scope.png\" style=\"width: 70%\">\n",
    "\n",
    "Nowadays, there are a lot of MLOps tools.\n",
    "\n",
    "Be aware, even if a tool offers features for given task, they may tackle it with different levels of depth.   \n",
    "For example, even though Kubeflow offers experiment tracking, it requires a level of DevOps expertise that most data scientist don't have. It sits on top of Kubernetes and can be seen as orchestrator for common MLOps tools. **Mlflow, on the other hand, is simple and perfect for global EDA and ML tracking**. \n",
    "\n",
    "Weights and Biases excels in tracking and reporting, considered to be a great tool for teams focused more on research than deliverables. Although it provides deployment capabilities, such as the ability for packaging models into Docker containers, it is not one of its strong suits.\n",
    "\n",
    "Comet.ml is another great example of tool that provides most of the same features as Mlflow, with superior tracking capabilities. Is is, however, a proprietary and licensed tool, just like W&B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1c365",
   "metadata": {},
   "source": [
    "# Is it perfect?\n",
    "\n",
    "**NO.**\n",
    "\n",
    "Although Mlflow is a great tool, it still lacks behind its competitors in some areas:\n",
    "\n",
    "- It is not easy to compare different experiments.\n",
    "- Even though super useful, autolog features are still experimental and sometimes buggy.\n",
    "- Most plots are not embedded widgets, but stored as artifacts.\n",
    "- Deployment containers are far from optimized, and they are not 100% reliable for a production environment.\n",
    "- ACL for registry management is only available through Databricks managed version.\n",
    "\n",
    "**In general, Mlflow offers a basic set of features if all you want is experiment tracking.   \n",
    "On the other hand, it is an open-source, language and library-agnostic and provides an interesting set of model management features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ea452",
   "metadata": {},
   "source": [
    "# Mlflow tracking\n",
    "\n",
    "Mlflow offers an API for tracking and recording machine learning experiments metadata, images, and artifacts.   \n",
    "It also provides a nice UI for checking and querying the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c846a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:35:31.512147Z",
     "start_time": "2021-12-03T18:35:23.751225Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acef81f",
   "metadata": {},
   "source": [
    "### Scikit-learn DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ee088",
   "metadata": {},
   "source": [
    "First, we need to create or set a Mlflow experiment. An experiment groups `runs`, or model trainings/executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf82aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:36:36.769635Z",
     "start_time": "2021-12-03T18:36:35.645999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set an Mlflow experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9447b8c",
   "metadata": {},
   "source": [
    "Following that, we need to load our dataset and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf5ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:36:42.429740Z",
     "start_time": "2021-12-03T18:36:42.408335Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_iris, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0c791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:36:55.481927Z",
     "start_time": "2021-12-03T18:36:55.432179Z"
    }
   },
   "outputs": [],
   "source": [
    "df_iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537080b3",
   "metadata": {},
   "source": [
    "Let's also do a quick EDA to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c65736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:36:56.489942Z",
     "start_time": "2021-12-03T18:36:56.475262Z"
    }
   },
   "outputs": [],
   "source": [
    "df_iris.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c72adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:36:56.826843Z",
     "start_time": "2021-12-03T18:36:56.766998Z"
    }
   },
   "outputs": [],
   "source": [
    "df_iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f909c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:36:59.485447Z",
     "start_time": "2021-12-03T18:36:59.471907Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(iris.target).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ede0fd",
   "metadata": {},
   "source": [
    "We decided to use a Decision Tree as our classifier. Given that our feature columns are complete and we are using a tree-based classifier, there is no need for normalization/standardization of the features. Let's proceed by feeding our model the training data and getting the test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c080f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:37:16.639172Z",
     "start_time": "2021-12-03T18:37:07.340443Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start run\n",
    "\n",
    "# Define and log hyperparameters\n",
    "hps = {\n",
    "    'random_state': 0,\n",
    "    'max_depth': 2\n",
    "}\n",
    "\n",
    "# Fit model\n",
    "dt = DecisionTreeClassifier(**hps)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "# Get test set predictions\n",
    "y_pred = dt.predict(X_test)\n",
    "metrics = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Set Mlflow tags (default and custom)\n",
    "\n",
    "# Plot confusion matrix and log artifact\n",
    "cm = confusion_matrix(y_test, y_pred, labels=dt.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt.classes_)\n",
    "\n",
    "\n",
    "# Plot tree configuration and log figure\n",
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "tree.plot_tree(dt, ax=ax)\n",
    "\n",
    "\n",
    "# Define input and output signatures\n",
    "\n",
    "\n",
    "# Log model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f12571",
   "metadata": {},
   "source": [
    "Access `http://<your-docker-machine-ip>:5000` and we will go through the Mlflow tracking UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04645e",
   "metadata": {},
   "source": [
    "### TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e397e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:38:25.954204Z",
     "start_time": "2021-12-03T18:38:16.813291Z"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce471a9c",
   "metadata": {},
   "source": [
    "We are going to load Fashion MNIST data from Tensorflow Keras datasets and normalize the training and test data.\n",
    "We are loading images of fashion objects. The provided images are 3-dimensional tensors, whose values range from 0 to 255. Neural networks best behave when input values range from 0.0 to 1.0, therefore we need to normalize it.\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/tutorials/keras/classification_files/output_m4VEw8Ud9Quh_0.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5d4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:38:29.029406Z",
     "start_time": "2021-12-03T18:38:25.957305Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load input data from tf.keras.datasets\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5de50d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:38:30.111938Z",
     "start_time": "2021-12-03T18:38:29.529031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize train and test data.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec896398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:38:31.708499Z",
     "start_time": "2021-12-03T18:38:31.631715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set a Mlflow experiment and turn on autologging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef50975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:39:22.090030Z",
     "start_time": "2021-12-03T18:38:37.444184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Keras model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Notice these metrics are not logged\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38c626",
   "metadata": {},
   "source": [
    "Let's go to the UI again and check how our loss and accuracy behaves during the training epochs.\n",
    "\n",
    "Besides being an experimental feature, subject to bugs, not every metric is automatically tracked by Mlflow.   \n",
    "For more information on which metrics are tracked, check the [docs](https://mlflow.org/docs/latest/tracking.html#tensorflow-and-keras-experimental)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda0576",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using XGBoost and HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6200e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:00:54.629036Z",
     "start_time": "2021-12-03T19:00:54.622008Z"
    }
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a24263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:00:55.086109Z",
     "start_time": "2021-12-03T19:00:55.065852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Iris dataset from scikit-learn and configure XGBoost data matrices\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_iris, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934d93f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:00:55.479471Z",
     "start_time": "2021-12-03T19:00:55.469416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparameter space\n",
    "space={\n",
    "    'max_depth': hp.quniform(\"max_depth\", 2, 6, 1),\n",
    "    'gamma': hp.uniform ('gamma', 1, 9),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 0, 5, 1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.2, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa7495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:00:56.125137Z",
     "start_time": "2021-12-03T19:00:56.097613Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set Mlflow experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309e14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:00:57.177321Z",
     "start_time": "2021-12-03T19:00:57.143699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure training data matrices (always after setting up autolog to infer signature)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ca3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:01:02.853573Z",
     "start_time": "2021-12-03T19:01:02.836451Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create training function\n",
    "def hyperparameter_tuning(space):\n",
    "    \n",
    "    # specify parameters via map\n",
    "    param = {\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'gamma': space['gamma'],\n",
    "        'reg_alpha': space['reg_alpha'],\n",
    "        'reg_lambda': space['reg_lambda'],\n",
    "        'colsample_bytree': space['colsample_bytree'],\n",
    "        'min_child_weight': 3,\n",
    "        'eta': 0.3,  # the training step for each iteration\n",
    "        'verbosity': 1,  # logging mode - quiet\n",
    "        'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': pd.Series(iris.target).nunique()\n",
    "    }\n",
    "    num_round = 2\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict(dtest)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "    f1 = f1_score(best_preds, y_test, average='macro')\n",
    "\n",
    "    #change the metric if you like\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'model': bst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fa316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:16.374081Z",
     "start_time": "2021-12-03T19:01:04.455955Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run hyperparameter optimization with HyperOpt\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e26f4",
   "metadata": {},
   "source": [
    "Let's now access the UI and plot the hyperparameters and metrics.   \n",
    "Check which hyperparameter ranges had the most impact on the model F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827b697",
   "metadata": {},
   "source": [
    "Finally, we want to retrive the best model, but we also need to know the ID of our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8efca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:58:13.783145Z",
     "start_time": "2021-12-03T18:58:13.742540Z"
    }
   },
   "outputs": [],
   "source": [
    "# List experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ee682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:23.239592Z",
     "start_time": "2021-12-03T19:02:21.871642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Search through experiment runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff122ed0",
   "metadata": {},
   "source": [
    "Having access to the `run_id` of the best performing model in our experiment, we can again get the model artifact, as well as other artifacts stored in our repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da8405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:31.653745Z",
     "start_time": "2021-12-03T19:02:31.368871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get best model artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e25e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:31.739453Z",
     "start_time": "2021-12-03T19:02:31.714467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute again the F1-Score against the test set\n",
    "best_preds = np.asarray([np.argmax(line) for line in bst.predict(dtest)])\n",
    "f1_score(best_preds, y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855fe51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:32.129683Z",
     "start_time": "2021-12-03T19:02:32.005332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download feature importance image artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407abb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:32.277548Z",
     "start_time": "2021-12-03T19:02:32.266531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display image artifact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad6dd8",
   "metadata": {},
   "source": [
    "## Mlflow Projects\n",
    "\n",
    "Our next goal is to create a reproducible code base for our model. Mlflow provides a format for packaging data science code so that we are able to easily reuse it.\n",
    "\n",
    "We only need four things:\n",
    "\n",
    "- A folder with the name of the project;\n",
    "- A `conda.yml` file or a docker image for the running environment;\n",
    "- A `.sh` or `.py` entrypoint file;\n",
    "- A `MLproject` file that contains the project definition.\n",
    "\n",
    "Having all these, we can simply run in our terminal:\n",
    "\n",
    "```\n",
    "mlflow run <PROJECT_NAME> --experiment-name <EXPERIMENT_NAME> [-P parameter1=value1 ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46ec4b",
   "metadata": {},
   "source": [
    "## Mlflow Models\n",
    "\n",
    "An MLflow Model is a standard format for packaging machine learning models that can be used in a variety of downstream tools—for example, real-time serving through a REST API or batch inference on Apache Spark. The format defines a convention that lets you save a model in different \"flavors\" that can be understood by different downstream tools.\n",
    "\n",
    "Let's check our XGBoost model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e6e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:35.332433Z",
     "start_time": "2021-12-03T19:02:35.048774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Python function version of XGBoost model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bb543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:35.411362Z",
     "start_time": "2021-12-03T19:02:35.401121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a68d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:02:36.247261Z",
     "start_time": "2021-12-03T19:02:36.200547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict with sample input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e82b7d",
   "metadata": {},
   "source": [
    "Mlflow Models provide a standard format so that one can load a model in different flavors. For example:\n",
    "- A pickled scikit-learn object that can be loaded into a Scikit-learn pipeline.\n",
    "- A generic Python function that can be loaded into any compatible Python environment, or any of the available deployment tools.\n",
    "\n",
    "If any of the available flavors that Mlflow provides does not fit your needs, one can define a custom model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a55a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:14:00.509913Z",
     "start_time": "2021-12-03T19:14:00.459432Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Define the model class\n",
    "\n",
    "\n",
    "# Construct and save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2189e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:14:04.371849Z",
     "start_time": "2021-12-03T19:14:04.278316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model in `python_function` format\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "# Evaluate the model\n",
    "model_input = pd.DataFrame([range(10)])\n",
    "model_output = loaded_model.predict(model_input)\n",
    "assert model_output.equals(pd.DataFrame([range(5, 15)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac1d82",
   "metadata": {},
   "source": [
    "## Built-in deployment tools\n",
    "\n",
    "Mlflow provides a series of built-in deployment tools, so that one can serve a model locally, or remotely in Azure ML, AWS SageMaker, or as a Apache Spark UDF.\n",
    "\n",
    "The tool builds a Docker images with REST API endpoints using Mlflow Python functions, that accepts data in multiple formats as POST input to the `/invocations` endpoint path:\n",
    "\n",
    "| Description                                                    | Content-Type\n",
    "|:---------------------------------------------------------------|:-------------------------------------------------------------------------|\n",
    "| JSON-serialized pandas DataFrames in the split orientation <br />  `pandas_df.to_json(orient='split')`     | `application/json` or `application/json; format=pandas-split` |\n",
    "| JSON-serialized pandas DataFrames in the records orientation <br />   | `application/json; format=pandas-records`                                |\n",
    "| CSV-serialized pandas DataFrames <br /> `pandas_df.to_csv()`                           | `text/csv`                                                                |\n",
    "| Tensor input formatted as described in TF Serving’s API docs. | `application/json`|\n",
    "\n",
    "To serve a model locally, one can simply run:\n",
    "\n",
    "```\n",
    "mlflow models serve -m \"models:/<MODEL_NAME>/<MODEL_VERSION_OR_STAGE>\" -p 1234\n",
    "```\n",
    "\n",
    "Where `<MODEL_VERSION_OR_STAGE>` may correspond to the model version or the stage (Staging, Production)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12411b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T23:17:56.036832Z",
     "start_time": "2021-12-02T23:17:55.982822Z"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.post(\n",
    "    'http://127.0.0.1:1234/invocations',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    data=X_test.to_json(orient='split'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b25bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T19:14:15.343576Z",
     "start_time": "2021-12-03T19:14:15.300534Z"
    }
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest versions on Production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2506f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T18:15:34.203119Z",
     "start_time": "2021-11-28T18:15:34.193560Z"
    }
   },
   "source": [
    "# Resources and references\n",
    "\n",
    "- [Mlflow](https://mlflow.org)\n",
    "- [ML workspace](https://github.com/ml-tooling/ml-workspace)\n",
    "- [mlflow-docker](https://github.com/Toumash/mlflow-docker)\n",
    "- [Ambiata - MLOps tools](https://www.ambiata.com/blog/2020-12-07-mlops-tools/)\n",
    "- [The Cheesy analogy of Mlflow and Kubeflow](https://servian.dev/the-cheesy-analogy-of-mlflow-and-kubeflow-715a45580fbe)\n",
    "- [Machine learning tools comparison](https://www.netguru.com/blog/machine-learning-tools-comparison)\n",
    "- [Decision Trees - scikit-learn](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    "- [Basic classification: Classify images of clothing](https://www.tensorflow.org/tutorials/keras/classification)\n",
    "- [HyperParameter Tuning — Hyperopt Bayesian Optimization](https://medium.com/analytics-vidhya/hyperparameter-tuning-hyperopt-bayesian-optimization-for-xgboost-and-neural-network-8aedf278a1c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5dc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
